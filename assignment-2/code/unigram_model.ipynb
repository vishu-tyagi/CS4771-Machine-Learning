{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XRjWiowaVKFN"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import random\n",
        "os.chdir('/content/drive/MyDrive/ML/hw2')\n",
        "\n",
        "from utils import *\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import scipy\n",
        "from scipy import sparse\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "from tqdm import tqdm\n",
        "import progressbar\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "tqdm.pandas()\n",
        "\n",
        "import pprint as pp\n",
        "pp = pp.PrettyPrinter(indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = load_data(merge=False)\n",
        "\n",
        "print(f'Number of training samples: {train.shape[0]}')\n",
        "print(f'Number of test samples: {test.shape[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcV8OErzZtE5",
        "outputId": "098699a2-8787-4319-fc8a-51467224c745"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 1000000\n",
            "Number of test samples: 320122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_model = UnigramModel()\n",
        "\n",
        "unigram_model.build_vocab(data=train, unigram_threshold=3000)\n",
        "print(f'\\n\\nNumber of features in unigram vocabulary: {len(unigram_model.unigram_vocab)}')\n",
        "print(f'Few sample features in unigram vocabulary:: {[word for word in unigram_model.unigram_vocab][300:305]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRks2C9Y3LME",
        "outputId": "bad58dd2-dcd9-485c-848f-ef397482502a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000000/1000000 [00:46<00:00, 21574.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Number of features in unigram vocabulary: 2440\n",
            "Few sample features in unigram vocabulary:: ['bruschetta', 'btw', 'buck', 'bucks', 'buddy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Term Frequency - Unigram Model"
      ],
      "metadata": {
        "id": "YKMCzy0yu3nO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_uni_tf, idf = unigram_model.tf(data=train, type='train')\n",
        "print(f'\\n\\nTerm Frequency unigram matrix shape (no lift) for train data: {train_uni_tf.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eef57a4-7666-475d-fd82-070d06b45823",
        "id": "XZDRbvKjuyhX"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000000/1000000 [04:16<00:00, 3902.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Term Frequency unigram matrix shape (no lift) for train data: (1000000, 2440)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "clf_uni_tf = Perceptron(unigram_model.unigram_vocab_size)\n",
        "clf_uni_tf.fit(train.label.tolist(), train_uni_tf)\n",
        "\n",
        "print(f'\\nWeight vector shape (lifted): {clf_uni_tf.w_avg.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOaFWG7QuqF0",
        "outputId": "0d0266b8-df39-42dc-9ca4-b2b5c320eb3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000000/1000000 [09:13<00:00, 1805.79it/s]\n",
            "100%|██████████| 1000000/1000000 [10:00<00:00, 1665.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Weight vector shape (lifted): (2441, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_unigram_w = clf_uni_tf.w_avg[1:, :].reshape(-1,).tolist()\n",
        "inv_vocab = {unigram_model.unigram_vocab[word]:word for word in unigram_model.unigram_vocab}\n",
        "\n",
        "lowest_weights = sorted([[tf_unigram_w[i], i] for i in range(len(tf_unigram_w))], key=lambda x: x[0])[0:10]\n",
        "lowest_weights_idx = [elem[1] for elem in lowest_weights]\n",
        "lowest_weight_words = [inv_vocab[val] for val in lowest_weights_idx]\n",
        "\n",
        "print(f'Words with lowest weights: \\n{lowest_weight_words}')\n",
        "print(f'\\n\\n{list(zip(lowest_weight_words, np.array(lowest_weights).T[0].round(2).tolist()))}')\n",
        "\n",
        "highest_weights = sorted([[tf_unigram_w[i], i] for i in range(len(tf_unigram_w))], key=lambda x: x[0], reverse=True)[0:10]\n",
        "highest_weights_idx = [elem[1] for elem in highest_weights]\n",
        "highest_weights_words = [inv_vocab[val] for val in highest_weights_idx]\n",
        "\n",
        "print(f'\\n\\n\\nWords with highest weights: \\n{highest_weights_words}')\n",
        "print(f'\\n\\n{list(zip(highest_weights_words, np.array(highest_weights).T[0].round(2).tolist()))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtIc5ck0e_nR",
        "outputId": "3d2d6a89-790c-42cc-f4d0-c043895c1846"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words with lowest weights: \n",
            "['worst', 'lacked', 'flavorless', 'mediocre', 'tasteless', 'disgusting', 'meh', 'hopes', 'disappointing', 'ruined']\n",
            "\n",
            "\n",
            "[('worst', -195.13), ('lacked', -172.04), ('flavorless', -171.44), ('mediocre', -165.33), ('tasteless', -156.61), ('disgusting', -153.9), ('meh', -148.58), ('hopes', -140.19), ('disappointing', -138.8), ('ruined', -134.33)]\n",
            "\n",
            "\n",
            "\n",
            "Words with highest weights: \n",
            "['perfection', 'heaven', 'gem', 'disappoint', 'heavenly', 'phenomenal', 'incredible', 'perfect', 'superb', 'perfectly']\n",
            "\n",
            "\n",
            "[('perfection', 149.69), ('heaven', 131.65), ('gem', 129.63), ('disappoint', 124.89), ('heavenly', 124.74), ('phenomenal', 117.8), ('incredible', 117.78), ('perfect', 107.1), ('superb', 103.77), ('perfectly', 102.82)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_uni_tf = unigram_model.tf(data=test, type='test')\n",
        "print(f'\\n\\nTerm Frequency unigram matrix shape (no lift) for test data: {test_uni_tf.shape}')"
      ],
      "metadata": {
        "id": "levKCu59uyhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32529e64-0b3a-4fe8-ae29-2407649c0668"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320122/320122 [00:56<00:00, 5637.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Term Frequency unigram matrix shape (no lift) for test data: (320122, 2440)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate\n",
        "train_scores = clf_uni_tf.evaluate(train.label.tolist(), train_uni_tf)\n",
        "test_scores = clf_uni_tf.evaluate(test.label.tolist(), test_uni_tf)\n",
        "\n",
        "print(f'TF unigram train scores:\\t accuracy:{train_scores[0]:.3f}, precision:{train_scores[1]:.3f}, recall:{train_scores[2]:.3f}')\n",
        "print(f'TF unigram test scores:\\t accuracy:{test_scores[0]:.3f}, precision:{test_scores[1]:.3f}, recall:{test_scores[2]:.3f}')\n"
      ],
      "metadata": {
        "id": "PQy11V1XuyhY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e8799f-d1b0-41f1-a696-dbfd187a002f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF unigram train scores:\t accuracy:0.889, precision:0.906, recall:0.929\n",
            "TF unigram test scores:\t accuracy:0.888, precision:0.905, recall:0.928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Term Frequencey Inverse Document Frequency (TF-IDF) - Unigram Model"
      ],
      "metadata": {
        "id": "SzTqMwQzuyhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_uni_tfidf = unigram_model.tfidf(data=train, term_frequency_mat=train_uni_tf, idf_mat=idf)\n",
        "print(f'\\n\\nTF-IDF unigram matrix shape (w/o lift) for train data: {train_uni_tfidf.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5cf1f98-0606-422d-c96e-0fd42e40464f",
        "id": "4pbhIiE2uyhZ"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "TF-IDF unigram matrix shape (w/o lift) for train data: (1000000, 2440)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "clf_uni_tfidf = Perceptron(unigram_model.unigram_vocab_size)\n",
        "clf_uni_tfidf.fit(train.label.tolist(), train_uni_tfidf)\n",
        "\n",
        "print(f'\\nWeight vector shape (lifted): {clf_uni_tfidf.w_avg.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QMXk-Fn4u19",
        "outputId": "6ada02ea-6133-4857-f4e9-ea219a3c3ce3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000000/1000000 [08:45<00:00, 1901.34it/s]\n",
            "100%|██████████| 1000000/1000000 [09:15<00:00, 1798.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Weight vector shape (lifted): (2441, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_unigram_w = clf_uni_tfidf.w_avg[1:, :].reshape(-1,).tolist()\n",
        "inv_vocab = {unigram_model.unigram_vocab[word]:word for word in unigram_model.unigram_vocab}\n",
        "\n",
        "lowest_weights = sorted([[tfidf_unigram_w[i], i] for i in range(len(tfidf_unigram_w))], key=lambda x: x[0])[0:10]\n",
        "lowest_weights_idx = [elem[1] for elem in lowest_weights]\n",
        "lowest_weight_words = [inv_vocab[val] for val in lowest_weights_idx]\n",
        "\n",
        "print(f'Words with lowest weights: \\n{lowest_weight_words}')\n",
        "print(f'\\n\\n{list(zip(lowest_weight_words, np.array(lowest_weights).T[0].round(2).tolist()))}')\n",
        "\n",
        "highest_weights = sorted([[tfidf_unigram_w[i], i] for i in range(len(tfidf_unigram_w))], key=lambda x: x[0], reverse=True)[0:10]\n",
        "highest_weights_idx = [elem[1] for elem in highest_weights]\n",
        "highest_weights_words = [inv_vocab[val] for val in highest_weights_idx]\n",
        "\n",
        "print(f'\\n\\n\\nWords with highest weights: \\n{highest_weights_words}')\n",
        "print(f'\\n\\n{list(zip(highest_weights_words, np.array(highest_weights).T[0].round(2).tolist()))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z6UAUWpfUe8",
        "outputId": "fc8cd613-dae1-48d7-bea8-488a978295bf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words with lowest weights: \n",
            "['worst', 'mediocre', 'bland', 'flavorless', 'awful', 'horrible', 'tasteless', 'disappointing', 'meh', 'lacked']\n",
            "\n",
            "\n",
            "[('worst', -7.69), ('mediocre', -7.03), ('bland', -6.06), ('flavorless', -5.69), ('awful', -5.61), ('horrible', -5.52), ('tasteless', -5.42), ('disappointing', -5.37), ('meh', -5.36), ('lacked', -5.29)]\n",
            "\n",
            "\n",
            "\n",
            "Words with highest weights: \n",
            "['delicious', 'perfection', 'amazing', 'perfect', 'great', 'excellent', 'awesome', 'heavenly', 'gem', 'fantastic']\n",
            "\n",
            "\n",
            "[('delicious', 6.92), ('perfection', 6.32), ('amazing', 6.01), ('perfect', 5.84), ('great', 5.39), ('excellent', 5.38), ('awesome', 5.24), ('heavenly', 5.13), ('gem', 5.05), ('fantastic', 4.86)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_uni_tfidf = unigram_model.tfidf(data=test, term_frequency_mat=test_uni_tf, idf_mat=idf)\n",
        "print(f'\\n\\nTF-IDF unigram matrix shape (w/o lift) for test data: {test_uni_tfidf.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92dea7f4-64a7-4ea8-f4b0-c52daae53322",
        "id": "lY3j4VEHuyhZ"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "TF-IDF unigram matrix shape (w/o lift) for test data: (320122, 2440)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate\n",
        "train_scores = clf_uni_tfidf.evaluate(train.label.tolist(), train_uni_tfidf)\n",
        "test_scores = clf_uni_tfidf.evaluate(test.label.tolist(), test_uni_tfidf)\n",
        "\n",
        "print(f'TF-IDF unigram train scores:\\t accuracy:{train_scores[0]:.3f}, precision:{train_scores[1]:.3f}, recall:{train_scores[2]:.3f}')\n",
        "print(f'TF-IDF unigram test scores:\\t accuracy:{test_scores[0]:.3f}, precision:{test_scores[1]:.3f}, recall:{test_scores[2]:.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23111c4c-164a-4b51-afab-4f63c214275c",
        "id": "IeWzpG6Puyha"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF unigram train scores:\t accuracy:0.890, precision:0.905, recall:0.932\n",
            "TF-IDF unigram test scores:\t accuracy:0.889, precision:0.904, recall:0.931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7DoAjk7zd5YB"
      },
      "execution_count": 15,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "unigram_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}